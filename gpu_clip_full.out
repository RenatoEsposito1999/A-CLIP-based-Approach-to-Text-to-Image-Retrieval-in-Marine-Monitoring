Nome: logit_scale | Trainabile: True | Shape: torch.Size([])
Nome: visual_projection.weight | Trainabile: True | Shape: torch.Size([512, 768])
Nome: text_projection.weight | Trainabile: True | Shape: torch.Size([512, 512])
Trainable parameters: 655,361
Total parameters: 151,277,313
Parametri ottimizzati:
START TRAINING
./checkpoint_full_clip/checkpoint_34.pth
trainable params: 1,001,473 || all params: 152,278,785 || trainable%: 0.6577
Nome: base_model.model.logit_scale | Trainabile: True | Shape: torch.Size([])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.vision_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight | Trainabile: True | Shape: torch.Size([768, 8])
Nome: base_model.model.visual_projection.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 768])
Nome: base_model.model.visual_projection.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Nome: base_model.model.text_projection.lora_A.default.weight | Trainabile: True | Shape: torch.Size([8, 512])
Nome: base_model.model.text_projection.lora_B.default.weight | Trainabile: True | Shape: torch.Size([512, 8])
Epoch 35/68, Loss: 1.5471
START VALIDATION
{'COCO_TURTLE_R@1': 0.4973105192184448, 'COCO_TURTLE_R@5': 0.6703887581825256, 'COCO_TURTLE_R@10': 0.7496424913406372, 'COCO_TURTLE_mean_rank': 13.353577613830566, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.8992521988934483, 'ONLY_TURTLE_val_loss': 4.36909451155827, 'train_loss': 1.547107102441006, 'epoch': 35}
Best model on only turtle set saved at epoch 35 with only_turtle_val_loss 4.3691
Epoch 36/68, Loss: 1.5477
START VALIDATION
{'COCO_TURTLE_R@1': 0.49724245071411133, 'COCO_TURTLE_R@5': 0.6694355607032776, 'COCO_TURTLE_R@10': 0.749302089214325, 'COCO_TURTLE_mean_rank': 13.479471206665039, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9164660490792373, 'ONLY_TURTLE_val_loss': 4.371169435566869, 'train_loss': 1.54765786206136, 'epoch': 36}
Epoch 37/68, Loss: 1.5456
START VALIDATION
{'COCO_TURTLE_R@1': 0.4969020187854767, 'COCO_TURTLE_R@5': 0.6698440313339233, 'COCO_TURTLE_R@10': 0.750255286693573, 'COCO_TURTLE_mean_rank': 13.425137519836426, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9099617415461048, 'ONLY_TURTLE_val_loss': 4.373328985839055, 'train_loss': 1.5456346757099277, 'epoch': 37}
Epoch 38/68, Loss: 1.5496
START VALIDATION
{'COCO_TURTLE_R@1': 0.49710625410079956, 'COCO_TURTLE_R@5': 0.6692312955856323, 'COCO_TURTLE_R@10': 0.7497106194496155, 'COCO_TURTLE_mean_rank': 13.457343101501465, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9009716551879356, 'ONLY_TURTLE_val_loss': 4.372774165252159, 'train_loss': 1.5496023517163073, 'epoch': 38}
Epoch 39/68, Loss: 1.5440
START VALIDATION
{'COCO_TURTLE_R@1': 0.4975147843360901, 'COCO_TURTLE_R@5': 0.6703206896781921, 'COCO_TURTLE_R@10': 0.7494382262229919, 'COCO_TURTLE_mean_rank': 13.21188735961914, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9133628689009567, 'ONLY_TURTLE_val_loss': 4.37170672416687, 'train_loss': 1.543961111150804, 'epoch': 39}
Epoch 40/68, Loss: 1.5479
START VALIDATION
{'COCO_TURTLE_R@1': 0.4967658221721649, 'COCO_TURTLE_R@5': 0.6689589023590088, 'COCO_TURTLE_R@10': 0.7499829530715942, 'COCO_TURTLE_mean_rank': 12.958738327026367, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.904213163359412, 'ONLY_TURTLE_val_loss': 4.373187225440453, 'train_loss': 1.5478960881467725, 'epoch': 40}
Epoch 41/68, Loss: 1.5480
START VALIDATION
{'COCO_TURTLE_R@1': 0.4979914128780365, 'COCO_TURTLE_R@5': 0.669163167476654, 'COCO_TURTLE_R@10': 0.7492339611053467, 'COCO_TURTLE_mean_rank': 13.335125923156738, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9180898460848579, 'ONLY_TURTLE_val_loss': 4.368705285006556, 'train_loss': 1.5479752968569271, 'epoch': 41}
Best model on only turtle set saved at epoch 41 with only_turtle_val_loss 4.3687
Epoch 42/68, Loss: 1.5478
START VALIDATION
{'COCO_TURTLE_R@1': 0.49724245071411133, 'COCO_TURTLE_R@5': 0.6695716977119446, 'COCO_TURTLE_R@10': 0.7499829530715942, 'COCO_TURTLE_mean_rank': 13.488322257995605, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9075014796750298, 'ONLY_TURTLE_val_loss': 4.373421500469076, 'train_loss': 1.5477823595531652, 'epoch': 42}
Epoch 43/68, Loss: 1.5496
START VALIDATION
{'COCO_TURTLE_R@1': 0.49649348855018616, 'COCO_TURTLE_R@5': 0.6700482964515686, 'COCO_TURTLE_R@10': 0.750731885433197, 'COCO_TURTLE_mean_rank': 13.247361183166504, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9075796789136426, 'ONLY_TURTLE_val_loss': 4.372949731761012, 'train_loss': 1.549576264912965, 'epoch': 43}
Epoch 44/68, Loss: 1.5490
START VALIDATION
{'COCO_TURTLE_R@1': 0.49703818559646606, 'COCO_TURTLE_R@5': 0.6694355607032776, 'COCO_TURTLE_R@10': 0.7508000135421753, 'COCO_TURTLE_mean_rank': 13.159732818603516, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9101829898768459, 'ONLY_TURTLE_val_loss': 4.370955557658754, 'train_loss': 1.5490203079630116, 'epoch': 44}
Epoch 45/68, Loss: 1.5499
START VALIDATION
{'COCO_TURTLE_R@1': 0.4975147843360901, 'COCO_TURTLE_R@5': 0.6695716977119446, 'COCO_TURTLE_R@10': 0.7503914833068848, 'COCO_TURTLE_mean_rank': 13.214678764343262, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9104218667951123, 'ONLY_TURTLE_val_loss': 4.372789847439733, 'train_loss': 1.5499347233381429, 'epoch': 45}
Epoch 46/68, Loss: 1.5482
START VALIDATION
{'COCO_TURTLE_R@1': 0.4968339204788208, 'COCO_TURTLE_R@5': 0.6707972884178162, 'COCO_TURTLE_R@10': 0.7518894076347351, 'COCO_TURTLE_mean_rank': 13.132020950317383, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9035065605722625, 'ONLY_TURTLE_val_loss': 4.372857003376402, 'train_loss': 1.5481513689775936, 'epoch': 46}
Epoch 47/68, Loss: 1.5448
START VALIDATION
{'COCO_TURTLE_R@1': 0.49724245071411133, 'COCO_TURTLE_R@5': 0.6703206896781921, 'COCO_TURTLE_R@10': 0.75059574842453, 'COCO_TURTLE_mean_rank': 12.894599914550781, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9103820735010608, 'ONLY_TURTLE_val_loss': 4.372302071801547, 'train_loss': 1.5448319135142154, 'epoch': 47}
Epoch 48/68, Loss: 1.5497
START VALIDATION
{'COCO_TURTLE_R@1': 0.49758288264274597, 'COCO_TURTLE_R@5': 0.6710015535354614, 'COCO_TURTLE_R@10': 0.7503914833068848, 'COCO_TURTLE_mean_rank': 13.312929153442383, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.91398836826456, 'ONLY_TURTLE_val_loss': 4.3695684137015505, 'train_loss': 1.5496746609445478, 'epoch': 48}
Epoch 49/68, Loss: 1.5494
START VALIDATION
{'COCO_TURTLE_R@1': 0.49656155705451965, 'COCO_TURTLE_R@5': 0.6701844930648804, 'COCO_TURTLE_R@10': 0.7509361505508423, 'COCO_TURTLE_mean_rank': 13.19044017791748, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9095897859540478, 'ONLY_TURTLE_val_loss': 4.373682860670419, 'train_loss': 1.5493584011421828, 'epoch': 49}
Epoch 50/68, Loss: 1.5511
START VALIDATION
{'COCO_TURTLE_R@1': 0.49771904945373535, 'COCO_TURTLE_R@5': 0.6706610918045044, 'COCO_TURTLE_R@10': 0.75059574842453, 'COCO_TURTLE_mean_rank': 13.202628135681152, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9069627400102287, 'ONLY_TURTLE_val_loss': 4.374660759136595, 'train_loss': 1.5510571862830491, 'epoch': 50}
Epoch 51/68, Loss: 1.5466
START VALIDATION
{'COCO_TURTLE_R@1': 0.4974467158317566, 'COCO_TURTLE_R@5': 0.6700482964515686, 'COCO_TURTLE_R@10': 0.7516170740127563, 'COCO_TURTLE_mean_rank': 13.273847579956055, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9157025279669926, 'ONLY_TURTLE_val_loss': 4.372265166249768, 'train_loss': 1.5466393823506401, 'epoch': 51}
Epoch 52/68, Loss: 1.5500
START VALIDATION
{'COCO_TURTLE_R@1': 0.4968339204788208, 'COCO_TURTLE_R@5': 0.6692312955856323, 'COCO_TURTLE_R@10': 0.749302089214325, 'COCO_TURTLE_mean_rank': 13.447538375854492, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9030030431418583, 'ONLY_TURTLE_val_loss': 4.371257313366594, 'train_loss': 1.550035156187464, 'epoch': 52}
Epoch 53/68, Loss: 1.5485
START VALIDATION
{'COCO_TURTLE_R@1': 0.49758288264274597, 'COCO_TURTLE_R@5': 0.6699802279472351, 'COCO_TURTLE_R@10': 0.7511404156684875, 'COCO_TURTLE_mean_rank': 13.383604049682617, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9256630807087338, 'ONLY_TURTLE_val_loss': 4.372135717293312, 'train_loss': 1.5485248194366206, 'epoch': 53}
Epoch 54/68, Loss: 1.5476
START VALIDATION
{'COCO_TURTLE_R@1': 0.4968339204788208, 'COCO_TURTLE_R@5': 0.6701164245605469, 'COCO_TURTLE_R@10': 0.750255286693573, 'COCO_TURTLE_mean_rank': 13.103424072265625, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9066530445526386, 'ONLY_TURTLE_val_loss': 4.373484027796779, 'train_loss': 1.547581143555094, 'epoch': 54}
Epoch 55/68, Loss: 1.5459
START VALIDATION
{'COCO_TURTLE_R@1': 0.49758288264274597, 'COCO_TURTLE_R@5': 0.66868656873703, 'COCO_TURTLE_R@10': 0.7495063543319702, 'COCO_TURTLE_mean_rank': 13.460270881652832, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9028075686816512, 'ONLY_TURTLE_val_loss': 4.371497121350519, 'train_loss': 1.5459111000670762, 'epoch': 55}
Epoch 56/68, Loss: 1.5456
START VALIDATION
{'COCO_TURTLE_R@1': 0.4979233145713806, 'COCO_TURTLE_R@5': 0.6712738871574402, 'COCO_TURTLE_R@10': 0.7518213391304016, 'COCO_TURTLE_mean_rank': 13.109892845153809, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9251678359919582, 'ONLY_TURTLE_val_loss': 4.371469670328601, 'train_loss': 1.545588953084633, 'epoch': 56}
Epoch 57/68, Loss: 1.5461
START VALIDATION
{'COCO_TURTLE_R@1': 0.4969020187854767, 'COCO_TURTLE_R@5': 0.6696397662162781, 'COCO_TURTLE_R@10': 0.7503914833068848, 'COCO_TURTLE_mean_rank': 13.353781700134277, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9117359354578216, 'ONLY_TURTLE_val_loss': 4.3707231982000945, 'train_loss': 1.5460800462570348, 'epoch': 57}
Epoch 58/68, Loss: 1.5503
START VALIDATION
{'COCO_TURTLE_R@1': 0.49717435240745544, 'COCO_TURTLE_R@5': 0.6695716977119446, 'COCO_TURTLE_R@10': 0.7494382262229919, 'COCO_TURTLE_mean_rank': 13.044733047485352, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9154953504430836, 'ONLY_TURTLE_val_loss': 4.369922087110322, 'train_loss': 1.550313738525891, 'epoch': 58}
Epoch 59/68, Loss: 1.5448
START VALIDATION
{'COCO_TURTLE_R@1': 0.4973786175251007, 'COCO_TURTLE_R@5': 0.6700482964515686, 'COCO_TURTLE_R@10': 0.7511404156684875, 'COCO_TURTLE_mean_rank': 13.326478958129883, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9153885409749787, 'ONLY_TURTLE_val_loss': 4.374606424364551, 'train_loss': 1.5447559752425208, 'epoch': 59}
Epoch 60/68, Loss: 1.5455
START VALIDATION
{'COCO_TURTLE_R@1': 0.4967658221721649, 'COCO_TURTLE_R@5': 0.6697759628295898, 'COCO_TURTLE_R@10': 0.7495744228363037, 'COCO_TURTLE_mean_rank': 13.154694557189941, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9173961240669777, 'ONLY_TURTLE_val_loss': 4.37375493707328, 'train_loss': 1.5455420803828317, 'epoch': 60}
Epoch 61/68, Loss: 1.5473
START VALIDATION
{'COCO_TURTLE_R@1': 0.49758288264274597, 'COCO_TURTLE_R@5': 0.6703206896781921, 'COCO_TURTLE_R@10': 0.7488935589790344, 'COCO_TURTLE_mean_rank': 13.412200927734375, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.908927438587978, 'ONLY_TURTLE_val_loss': 4.372673388185172, 'train_loss': 1.5473405342610156, 'epoch': 61}
Epoch 62/68, Loss: 1.5459
START VALIDATION
{'COCO_TURTLE_R@1': 0.4964253902435303, 'COCO_TURTLE_R@5': 0.668346107006073, 'COCO_TURTLE_R@10': 0.7500510215759277, 'COCO_TURTLE_mean_rank': 13.48484992980957, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9105721917645684, 'ONLY_TURTLE_val_loss': 4.371827170766633, 'train_loss': 1.5458569937064999, 'epoch': 62}
Epoch 63/68, Loss: 1.5438
START VALIDATION
{'COCO_TURTLE_R@1': 0.4974467158317566, 'COCO_TURTLE_R@5': 0.6702525615692139, 'COCO_TURTLE_R@10': 0.7515489459037781, 'COCO_TURTLE_mean_rank': 13.282221794128418, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9079624476103947, 'ONLY_TURTLE_val_loss': 4.372409047751591, 'train_loss': 1.5438239789399943, 'epoch': 63}
Epoch 64/68, Loss: 1.5519
START VALIDATION
{'COCO_TURTLE_R@1': 0.4975147843360901, 'COCO_TURTLE_R@5': 0.6712058186531067, 'COCO_TURTLE_R@10': 0.7521617412567139, 'COCO_TURTLE_mean_rank': 13.236194610595703, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.899613160511543, 'ONLY_TURTLE_val_loss': 4.3707402451285, 'train_loss': 1.5518693195991828, 'epoch': 64}
Epoch 65/68, Loss: 1.5505
START VALIDATION
{'COCO_TURTLE_R@1': 0.4975147843360901, 'COCO_TURTLE_R@5': 0.6707972884178162, 'COCO_TURTLE_R@10': 0.7503234148025513, 'COCO_TURTLE_mean_rank': 13.281200408935547, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9205104893651501, 'ONLY_TURTLE_val_loss': 4.3706226554410215, 'train_loss': 1.5504619488950635, 'epoch': 65}
Epoch 66/68, Loss: 1.5475
START VALIDATION
{'COCO_TURTLE_R@1': 0.4966977536678314, 'COCO_TURTLE_R@5': 0.6698440313339233, 'COCO_TURTLE_R@10': 0.7512766122817993, 'COCO_TURTLE_mean_rank': 13.464764595031738, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9039642625841602, 'ONLY_TURTLE_val_loss': 4.365786548318534, 'train_loss': 1.54751861193141, 'epoch': 66}
Best model on only turtle set saved at epoch 66 with only_turtle_val_loss 4.3658
Epoch 67/68, Loss: 1.5427
START VALIDATION
{'COCO_TURTLE_R@1': 0.49703818559646606, 'COCO_TURTLE_R@5': 0.6695036292076111, 'COCO_TURTLE_R@10': 0.7503914833068848, 'COCO_TURTLE_mean_rank': 13.819295883178711, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.9075326775682384, 'ONLY_TURTLE_val_loss': 4.372447449585487, 'train_loss': 1.542669466284455, 'epoch': 67}
Epoch 68/68, Loss: 1.5472
START VALIDATION
{'COCO_TURTLE_R@1': 0.49710625410079956, 'COCO_TURTLE_R@5': 0.6705249547958374, 'COCO_TURTLE_R@10': 0.7494382262229919, 'COCO_TURTLE_mean_rank': 12.981683731079102, 'TURTLE_ONLY_R@1': 1.0, 'TURTLE_ONLY_R@5': 1.0, 'TURTLE_ONLY_R@10': 1.0, 'TURTLE_ONLY_mean_rank': 0.0, 'COCO_TURTLE_val_loss': 1.908811560992537, 'ONLY_TURTLE_val_loss': 4.37119185102397, 'train_loss': 1.5471679617146976, 'epoch': 68}

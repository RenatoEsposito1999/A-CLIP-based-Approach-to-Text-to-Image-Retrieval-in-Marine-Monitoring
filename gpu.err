Using cache found in /root/.cache/torch/hub/facebookresearch_dinov2_main
/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)
  warnings.warn("xFormers is available (SwiGLU)")
/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)
  warnings.warn("xFormers is available (Attention)")
/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)
  warnings.warn("xFormers is available (Block)")
  0%|          | 0/3642 [00:00<?, ?it/s]100%|██████████| 3642/3642 [00:00<00:00, 835009.03it/s]
  0%|          | 0/50 [00:00<?, ?it/s]/workspace/text-to-image-retrivial/src/loss.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  flags = torch.tensor(flags)
  0%|          | 0/50 [06:05<?, ?it/s]
Traceback (most recent call last):
  File "/workspace/text-to-image-retrivial/main.py", line 153, in <module>
    main(batch_size=args.bs, lr=args.lr, dim=args.dim, device= args.device, wd = args.wd)
  File "/workspace/text-to-image-retrivial/main.py", line 136, in main
    train(model=model, dataloader=train_dataloader,n_epochs=50, loss_fn=contrastiveLoss,device=device,optimizer=optimizer,scheduler=scheduler, writer=writer, val_dataloader=val_dataloader)
  File "/workspace/text-to-image-retrivial/src/train.py", line 38, in train
    def validation(dataloader, model,writer, train_epoch, device):
  File "/workspace/text-to-image-retrivial/src/train.py", line 60, in validation
    def compute_metrics(writer, text_embeddings, image_embeddings, epoch,k_values=[1, 5, 10], categories=None):
  File "/workspace/text-to-image-retrivial/src/train.py", line 66, in compute_metrics
    # Ottieni gli indici top-k (discendenti)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 166.41 GiB. GPU 0 has a total capacity of 23.54 GiB of which 21.99 GiB is free. Including non-PyTorch memory, this process has 1.53 GiB memory in use. Of the allocated memory 780.06 MiB is allocated by PyTorch, and 321.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
